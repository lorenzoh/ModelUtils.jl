var documenterSearchIndex = {"docs":
[{"location":"man/initialization/#Initialization-1","page":"Initialization","title":"Initialization","text":"","category":"section"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"CurrentModule = ModelUtils","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"ModelUtils.jl makes it easy to selectively initialize weights in your model even after it is created.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"The simplest case of initialization is when all layers of the same kind are initialized the same. We can represent that with an Initialization object.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"For example, Initialization(Dense, :W, Flux.zeros) means, for all Dense layers dense, initialize dense.W with initializer Flux.zeros.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"These initalizations can be applied with initmodel!.","category":"page"},{"location":"man/initialization/#Example-1","page":"Initialization","title":"Example","text":"","category":"section"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"Let's look at a real example where custom initialization is necessary.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"Flux's default initialization for a Conv layer's weight field is \"Glorot/Xavier uniform\". However, almost always one will use ReLU activations for CNNs, and it is known that \"Kaiming/He\" initialization works better for ReLU activations.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"That is why ModelUtils.jl exports init_kaiming_normal and init_kaiming_uniform.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"Let's see how we can reinitialize a small CNN with Kaiming initialization instead of Glorot.","category":"page"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"using Flux, ModelUtils # hide\ncnn = Chain(Conv((3, 3), 3 => 16, relu), Conv((3, 3), 16 => 16))\ninits = [Initialization(Conv, :weight, init_kaiming_normal)]\ninitmodel!(cnn, inits)","category":"page"},{"location":"man/initialization/#Custom-initializations-1","page":"Initialization","title":"Custom initializations","text":"","category":"section"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"If you want more control over which layers are initialized how, use IterLayers to iterate through your layers and initialize them one-by-one with init!","category":"page"},{"location":"man/initialization/#Initialization-reference-1","page":"Initialization","title":"Initialization reference","text":"","category":"section"},{"location":"man/initialization/#Helpers-1","page":"Initialization","title":"Helpers","text":"","category":"section"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"init!\ninitmodel!","category":"page"},{"location":"man/initialization/#Initializers-1","page":"Initialization","title":"Initializers","text":"","category":"section"},{"location":"man/initialization/#","page":"Initialization","title":"Initialization","text":"init_kaiming_normal\ninit_kaiming_uniform\ninit_zeros","category":"page"},{"location":"man/hooks/#Hooks-1","page":"Hooks","title":"Hooks","text":"","category":"section"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"Hooks are a feature that lets you add functions to a layer that are called on either the forward or the backward pass.","category":"page"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"Since Flux doesn't make any assumptions about your layers except them being callable as functions, Hooks are implemented as a wrapper layer, Hook.","category":"page"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"In most cases you will have an existing model that you want to add a hook to, and addhook does just that:","category":"page"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"using Flux, ModelUtils # hide\nmodel = Chain(Conv((3, 3), 3 => 16, relu), Conv((3, 3), 16 => 1, relu))\nhmodel = addhook(\n    model,\n    forward = (state, activation) -> println(summary(activation)),\n    backward = (state, gradient) -> println(summary(gradient)),\n    filter_fn = (layer) -> layer isa Conv\n)\nprintmodel(hmodel)","category":"page"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"You can also explicitly wrap a layer in a Hook:","category":"page"},{"location":"man/hooks/#","page":"Hooks","title":"Hooks","text":"layer = Dense(10, 10)\nhook = Hook(layer, forward = (state, activation) -> println(\"Hi!\"))\n\nhook(randn(10))","category":"page"},{"location":"man/custom/#Custom-models-1","page":"Custom models","title":"Custom models","text":"","category":"section"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"CurrentModule = ModelUtils","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"When wrapping a layer with Model, the layer struct's fieldnames are stored inside Model and are automatically classified into one of 3 categories:","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"model.paramattrs\nFields with trainable parameters.   By default all fields of type AbstractArray{T,<:AbstractFloat} are treated as trainable parameters\nmodel.childrenattrs   Fields that contain children layers. By default fields that are a Flux layer are treated as children.\nmodel.settingattrs    Fields with hyperparameters that define the layer structure, e.g. padding on a convolution. Default field category.","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"While this should work well for even many custom layers, in some cases you have to define what category a field is yourself.","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"The classification happens with dispatch on the function attrtype.","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"AttrType\nattrtype","category":"page"},{"location":"man/custom/#ModelUtils.AttrType","page":"Custom models","title":"ModelUtils.AttrType","text":"AttrType\n\nEnum for layer field types.\n\nParamAttr\nField with trainable parameters, e.g. Dense.W\nChildAttr\nField that contains children layers, e.g. Chain.layers\nSettingAttr\nFields with hyperparameters that define the layer structure, e.g. Conv.pad\n\n\n\n\n\n","category":"type"},{"location":"man/custom/#ModelUtils.attrtype","page":"Custom models","title":"ModelUtils.attrtype","text":"attrtype(layer::L, name::Val)::AttrType\n\nDispatch on a layer, and a field name (wrapped in a Val) to determine what AttrType the field is.\n\nIf there is no custom method defined, for a layer type and field name, attrtype will additionally dispatch on the field's value to give a reasonable default.\n\nBy default the layers will be classified as following:\n\nParamAttr\nFields of type AbstractArray{T,<:AbstractFloat} are treated as trainable   parameters\nChildAttr\nFields that are a Flux layer are treated as children.\nSettingAttr\nAny other\n\nTo customize for your type, define a method like\n\nattrtype(::MyLayer, ::Val{:myfieldname}) = ChildAttr\n\n\n\n\n\n","category":"function"},{"location":"man/custom/#Defining-a-custom-[attrtype](@ref)-method-1","page":"Custom models","title":"Defining a custom attrtype method","text":"","category":"section"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"Let's say we create a custom layer that's like Chain:","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"using Flux, ModelUtils # hide\nstruct MyChain\n    layers\n    MyChain(layers...) = new(layers)\nend\n(m::MyChain)(x) = foldl((x, layer) -> layer(x), m.layers, init = x)","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"Now we want MyChain.layers to be a ChildAttr but we can check that it is not classified as such:","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"mychain = MyChain(Dense(10, 10), Dense(10, 10), softmax)\nModelUtils.attrtype(mychain, Val(:layers))","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"So we can define a custom attrtype method:","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"import ModelUtils: attrtype\nModelUtils.attrtype(::MyChain, ::Val{:layers}) = ModelUtils.ChildAttr","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"And now we get the result we wanted:","category":"page"},{"location":"man/custom/#","page":"Custom models","title":"Custom models","text":"ModelUtils.attrtype(mychain, Val(:layers))","category":"page"},{"location":"lib/public/#Reference-1","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"lib/public/#","page":"Reference","title":"Reference","text":"Reference for ModelUtils.jl","category":"page"},{"location":"lib/public/#Index-1","page":"Reference","title":"Index","text":"","category":"section"},{"location":"lib/public/#","page":"Reference","title":"Reference","text":"Pages = [\"public.md\"]","category":"page"},{"location":"lib/public/#Public-Interface-1","page":"Reference","title":"Public Interface","text":"","category":"section"},{"location":"lib/public/#","page":"Reference","title":"Reference","text":"IterLayers\nIterModels\nModel\nHook\naddhook\nmapmodel\nparamsdict\ngradientsdict\nprintmodel\nInitialization\ninit_kaiming_normal\ninit_kaiming_uniform\ninit_zeros\ninit!\ninitmodel!","category":"page"},{"location":"lib/public/#ModelUtils.IterLayers","page":"Reference","title":"ModelUtils.IterLayers","text":"IterLayers(model::Model)\n\nPre-order (parents before children) iterator over all wrapped layers.\n\nExample\n\n> model = Model(Chain(Conv((3, 3), 3 => 16), BatchNorm(16)))\n> collect(IterModels(model))\n\n[Chain{...}, Conv{...}, BatchNorm{...}]\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.IterModels","page":"Reference","title":"ModelUtils.IterModels","text":"IterModels(model::Model)\n\nPre-order (parents before children) iterator over all Models. If you want to iterate over the wrapped layers instead, use IterLayers.\n\nExample\n\n> model = Model(Chain(Conv((3, 3), 3 => 16), BatchNorm(16)))\n> collect(IterModels(model))\n\n[Model{Chain{...}}, Model{Conv{...}}, Model{BatchNorm{...}}]\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.Model","page":"Reference","title":"ModelUtils.Model","text":"Model(layer)\n\nWrapper for Flux layer that recursively wraps children layers.\n\nUse model.layer to access wrapped layer\n\nUse children(model) to access children wrappers\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#ModelUtils.Hook","page":"Reference","title":"ModelUtils.Hook","text":"Hook(layer, [forward, backward, state = Dict()])\n\nWraps a Flux layer, and holds a Dict with state (Hook.state)\n\nAfter the forward pass of the wrapped layer calls Hook.forward(state, layeroutput) After the gradient calculation of the wrapped layer calls Hook.backward(state, layergradient)\n\nFor adding hooks to existing models, see addhook\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#ModelUtils.addhook","page":"Reference","title":"ModelUtils.addhook","text":"addhook(model; [forward, backward, filter_fn])\n\nAdd a Hook with callbacks forward and backward to all layers of model where filter_fn(layer) == true.\n\nSee Hook\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.mapmodel","page":"Reference","title":"ModelUtils.mapmodel","text":"mapmodel(f, model::M, [constructor])\n\nApplies f to every layer, resulting in a new model.\n\nwarning: Warning\nThe model layer structs are copied in the process, but the fields are not, hence the resulting model will have the same parameters!\n\nwarning: Warning\nThe copying is done by first recursively applying mapmodel to all children fields and then attempting to create a new object of type M with the default outer constructor M(fields...).\n\nIf your custom type does not have a constructor of that form, like e.g. Flux.Chain, you will have to extend this function with a signature like\n\n`mapmodel(f, model::MyType, (fields) -> ...)`\n\nwhere the last argument results in a MyType(fields...)\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.paramsdict","page":"Reference","title":"ModelUtils.paramsdict","text":"paramsdict(model::Model) -> Dict{Symbol, Array}\n\nReturn a Dict with mapping parameter name => parameter value.\n\nUseful for inspecting the distribution of parameters.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.gradientsdict","page":"Reference","title":"ModelUtils.gradientsdict","text":"gradientsdict(model::Model, gs::Grads) -> Dict{Symbol, Array}\n\nReturn a Dict with mapping parameter name => gradient value\n\nUseful for inspecting the distribution of gradients.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.printmodel","page":"Reference","title":"ModelUtils.printmodel","text":"printmodel(model)\n\nPrint model as a tree\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.Initialization","page":"Reference","title":"ModelUtils.Initialization","text":"Initialization(layertype, field, initializer)\n\nDescribes an initialization for field field of all layers of type layertype to be initialized with initializer.\n\nUse initmodel! to apply to a model.\n\nExample\n\nInitialization(Conv, :bias, init_zeros) -> initialize the bias of all Conv layers with zeros.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#ModelUtils.init_kaiming_normal","page":"Reference","title":"ModelUtils.init_kaiming_normal","text":"init_normal_uniform(T, dims...; gain=sqrt(2))\n\nKaiming normal initializer\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.init_kaiming_uniform","page":"Reference","title":"ModelUtils.init_kaiming_uniform","text":"init_kaiming_uniform(T, dims...; gain=sqrt(2))\n\nKaiming uniform initializer\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.init!","page":"Reference","title":"ModelUtils.init!","text":"init!(a, initializer)\n\nInitialize an array a with initializer.\n\nExample\n\nlayer = Conv((3, 3), 3 => 16)\ninit!(layer.weight, init_kaiming_normal)\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#ModelUtils.initmodel!","page":"Reference","title":"ModelUtils.initmodel!","text":"initmodel!(model, inits::Vector{Initialization})\n\nApplies inits to model.\n\nSee Initialization.\n\nExample\n\nmodel = Chain(Dense(10, 10), Dense(10, 10))\ninitmodel!(model, [\n    Initialization(Dense, :W, init_kaiming_normal),\n    Initialization(Dense, :bias, init_zeros)\n])\n\n\n\n\n\n","category":"function"},{"location":"#ModelUtils.jl-documentation-1","page":"Home","title":"ModelUtils.jl documentation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"CurrentModule = ModelUtils","category":"page"},{"location":"#","page":"Home","title":"Home","text":"ModelUtils.jl provides utilities for working with Flux.jl models.","category":"page"},{"location":"#Features-1","page":"Home","title":"Features","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"initialization\nhooks\niteration ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The most important type it defines is Model, a tree data structure that wraps your Flux model and is itself a Flux layer.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"ModelUtils.jl should work with all models that work with Flux, but for some custom types you might have to extend a few of ModelUtils.jls methods, see Custom models for more information.","category":"page"},{"location":"#Manual-1","page":"Home","title":"Manual","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\"man/basic.md\", \"man/hooks.md\", \"man/custom.md\", \"man/initialization.md\"]","category":"page"},{"location":"#Reference-1","page":"Home","title":"Reference","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\"lib/public.md\"]","category":"page"},{"location":"man/basic/#Getting-started-1","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"note: Note\nThis documentation assumes familiarity with Flux.jl and deep learning models in general.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"The most important type ModelUtils.jl defines is Model.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"It is a tree structure that wraps any Flux or custom layer, recursively wrapping all children layers too.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"To see what that is useful for, let's look at a simple Flux model:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"using Flux: BatchNorm, Conv, Chain\n\nchain = Chain(Conv((3, 3), 3 => 16), BatchNorm(16))\nnothing # hide","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"This model has an implicit tree structure, namely:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"Chain\nConv\nBatchNorm","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"Deep learning models often get very large and have multiple levels of hierarchy in their layers, so making this tree structure explicit helps to visualize and inspect a model.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"We can do this with the Model constructor:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"using ModelUtils: Model, printmodel\n\nmodel = Model(chain)","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"Note that Model can be called like any layer, and simply passes the input to the wrapped layer:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"x = randn(8, 8, 3, 1)\n@assert chain(x) ≈ model(x) ","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"Now we can show the model's tree structure with printmodel:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"printmodel(model)","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"You can see that the tree structure is indicated and that we get some additional information about each wrapped layer's fields.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"note: Note\nMany functions in ModelUtils.jl will work with unwrapped Flux models, but will wrap and unwrap the model in the function call. Since constructing the tree takes some time and memory, it is more performant to keep your model wrapped in a Model.","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"note: Note\nModelTools.jl will try to automatically detect which fields are trainable parameters, settings, or children layers. This should work for most custom layers, too, but if the result is not what you expect you can customize the behavior, see Custom models.","category":"page"},{"location":"man/basic/#Iteration-1","page":"Getting started","title":"Iteration","text":"","category":"section"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"We can also iterate over a Model in 2 ways:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"The first way is to iterate over the Model wrappers with IterModels:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"using Flux, ModelUtils # hide","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"model = Model(Chain(Conv((3, 3), 3 => 16), BatchNorm(16)))\ncollect(IterModels(model))","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"But it is also possible to iterate over the wrapped layers directly with IterLayers:","category":"page"},{"location":"man/basic/#","page":"Getting started","title":"Getting started","text":"model = Model(Chain(Conv((3, 3), 3 => 16), BatchNorm(16)))\ncollect(IterLayers(model))","category":"page"}]
}
